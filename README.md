---

# ğŸ¥— Yemek SipariÅŸi KiÅŸiselleÅŸtirme Projesi

Bu projede, mÃ¼ÅŸterilerin yemek sipariÅŸlerindeki "Items in order" aÃ§Ä±klamalarÄ±nÄ± doÄŸal dil iÅŸleme (NLP) yÃ¶ntemleri kullanarak analiz ederek kiÅŸiselleÅŸtirilmiÅŸ Ã¶neriler sunmak amaÃ§lanmÄ±ÅŸtÄ±r. Bu sayede mÃ¼ÅŸterilere daha iyi bir deneyim sunulmasÄ± ve sipariÅŸ sÃ¼reÃ§lerinin optimize edilmesi hedeflenmektedir.

---

## 1. Hafta â€” Veri HazÄ±rlama ve Ã–niÅŸleme
### 1.1. Veri Toplama
Ä°lk olarak, restoran ve yemek sipariÅŸ platformlarÄ±ndan mÃ¼ÅŸteri sipariÅŸ verileri toplanmÄ±ÅŸtÄ±r. Bu verilerden "Items in order" sÃ¼tunu ayrÄ±larak sipariÅŸ aÃ§Ä±klamalarÄ± elde edilmiÅŸtir.  
AyrÄ±lan "Items in order" sÃ¼tunlarÄ± birleÅŸtirilerek yeni bir CSV dosyasÄ± (`birlesik_siparisler.csv`) oluÅŸturulmuÅŸtur.  
Bu iÅŸlem, `siparis_birlestirme.ipynb` adlÄ± Jupyter Notebook dosyasÄ±nda gerÃ§ekleÅŸtirilmiÅŸtir.

### 1.2. Veri Ã–n Ä°ÅŸleme
"Items in order" verileri Ã¼zerinde aÅŸaÄŸÄ±daki iÅŸlemler uygulanmÄ±ÅŸtÄ±r:
- KÃ¼Ã§Ã¼k harfe Ã§evirme
- Noktalama iÅŸaretlerinin kaldÄ±rÄ±lmasÄ±
- Ä°ngilizce stopword (gereksiz kelimeler) temizliÄŸi
- Tokenizasyon (metni kelimelere ayÄ±rma)
- Lemmatizasyon (kelimelerin kÃ¶klerine indirgenmesi)
- Stemming (kelime kÃ¶klerini bulma)

---

## ğŸ” Proje Ã–zeti
CSV dosyasÄ±ndan alÄ±nan "Items in order" verileri ÅŸu adÄ±mlardan geÃ§irilmiÅŸtir:
- Verinin `pandas` ile yÃ¼klenmesi ve genel incelemesi
- Eksik verilerin kontrolÃ¼
- CÃ¼mle ve kelime seviyesinde ayrÄ±ÅŸtÄ±rma (`tokenization`)
- Ä°ngilizce stopwords (`nltk`) ile filtreleme
- Lemmatizasyon ve stemleme iÅŸlemleriyle kelimelerin kÃ¶k formlarÄ±nÄ±n Ã§Ä±karÄ±lmasÄ±
- SipariÅŸ listesi oluÅŸturularak yapÄ±sal analiz yapÄ±lmasÄ±
- Veri Ã¶n iÅŸleme adÄ±mlarÄ±, `nltk`, `pandas` ve `re` kÃ¼tÃ¼phaneleri kullanÄ±larak Python'da uygulanmÄ±ÅŸtÄ±r.

---

## ğŸ› ï¸ KullanÄ±lan Teknolojiler ve KÃ¼tÃ¼phaneler
- Python 3.x
- Jupyter Notebook
- [NLTK - Natural Language Toolkit](https://www.nltk.org/)
- spaCy (isteÄŸe baÄŸlÄ±)
- pandas
- numpy
- `gensim` (Word2Vec gibi kelime vektÃ¶rÃ¼ modelleri iÃ§in)
- `from gensim.models import Word2Vec` (Word2Vec modeli iÃ§in)
- `import pandas as pd` (Veri Ã§erÃ§eveleri ve CSV dosyalarÄ± iÃ§in)
- `import nltk` (NLP gÃ¶revleri iÃ§in)
- `from nltk.tokenize import word_tokenize, sent_tokenize` (Metni kelimelere ve cÃ¼mlelere ayÄ±rmak iÃ§in)
- `from nltk.corpus import stopwords` (Stop kelimelerini filtrelemek iÃ§in)
- `from nltk.stem import WordNetLemmatizer, PorterStemmer` (Kelime kÃ¶klerini bulmak iÃ§in)
- `from collections import Counter` (Kelime sÄ±klÄ±klarÄ±nÄ± saymak iÃ§in)

---

## 2. Hafta: TF-IDF VektÃ¶rleÅŸtirme ve Word2Vec Modelleri

Bu hafta, Ã¶n iÅŸlenmiÅŸ "Items in order" verileri hem TF-IDF yÃ¶ntemiyle vektÃ¶rleÅŸtirilecek hem de Word2Vec modeli kullanÄ±larak kelime vektÃ¶rleri elde edilecektir.

### 2.1. TF-IDF VektÃ¶rleÅŸtirme
TF-IDF (Term Frequency-Inverse Document Frequency), sipariÅŸ aÃ§Ä±klamalarÄ±ndaki kelimelerin Ã¶nemini Ã¶lÃ§mek iÃ§in kullanÄ±lan bir tekniktir. Bu adÄ±mda, her bir sipariÅŸ verisi, terim frekanslarÄ± (TF) ve ters belge frekansÄ± (IDF) kullanÄ±larak bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.  
`sklearn.feature_extraction.text` kÃ¼tÃ¼phanesindeki `TfidfVectorizer` sÄ±nÄ±fÄ± bu dÃ¶nÃ¼ÅŸÃ¼mÃ¼ gerÃ§ekleÅŸtirmek iÃ§in kullanÄ±lÄ±r.  
Bu iÅŸlem, kod klasÃ¶rÃ¼ndeki `TF-IDF.ipynb` dosyasÄ±nda gerÃ§ekleÅŸtirilmiÅŸtir. Elde edilen bulgular dosya iÃ§inde bulunmaktadÄ±r.

### 2.2. Cosine Similarity (KosinÃ¼s BenzerliÄŸi) HesaplamasÄ±
TF-IDF vektÃ¶rleri elde edildikten sonra, sipariÅŸler arasÄ±ndaki benzerliÄŸi Ã¶lÃ§mek iÃ§in Cosine Similarity yÃ¶ntemi kullanÄ±lÄ±r. Bu yÃ¶ntem, iki vektÃ¶r arasÄ±ndaki aÃ§Ä±nÄ±n kosinÃ¼sÃ¼nÃ¼ hesaplayarak sipariÅŸlerin ne kadar benzer olduÄŸunu belirler.  
`sklearn.metrics.pairwise` kÃ¼tÃ¼phanesindeki `cosine_similarity` fonksiyonu bu hesaplamayÄ± yapmak iÃ§in kullanÄ±lÄ±r.  
Bu iÅŸlem, kod klasÃ¶rÃ¼ndeki `TF-IDF.ipynb` dosyasÄ±nda gerÃ§ekleÅŸtirilmiÅŸtir. Elde edilen bulgular dosya iÃ§inde bulunmaktadÄ±r.

### 2.3. Ä°lk SipariÅŸ iÃ§in En YÃ¼ksek TF-IDF Skorlu Kelimeler
TF-IDF vektÃ¶rleÅŸtirme iÅŸleminden sonra, her sipariÅŸteki en Ã¶nemli kelimeler belirlenir. Bu, her sipariÅŸ iÃ§in en yÃ¼ksek TF-IDF skoruna sahip kelimelerin bulunmasÄ±yla yapÄ±lÄ±r.  
Bu analiz, veri setindeki sipariÅŸlerin anahtar temalarÄ±nÄ± (Ã¶rneÄŸin, sÄ±k sipariÅŸ edilen yemek tÃ¼rleri) anlamaya yardÄ±mcÄ± olur.

### 2.4. Cosine Similarity Matrisi OluÅŸturma
TÃ¼m sipariÅŸler arasÄ±ndaki Cosine Similarity skorlarÄ± bir matris iÃ§inde dÃ¼zenlenir. Bu matris, hangi sipariÅŸlerin birbirine daha Ã§ok benzediÄŸini gÃ¶rselleÅŸtirmeyi ve analiz etmeyi kolaylaÅŸtÄ±rÄ±r.  
Bu matris, kiÅŸiselleÅŸtirilmiÅŸ Ã¶neri sistemleri veya benzer sipariÅŸ gruplarÄ±nÄ± bulma gibi uygulamalar iÃ§in temel oluÅŸturabilir.

### 2.5. Word2Vec Modelleri EÄŸitimi
Word2Vec modeli, sipariÅŸ aÃ§Ä±klamalarÄ±ndaki kelimelerin anlamlarÄ±nÄ± vektÃ¶rler aracÄ±lÄ±ÄŸÄ±yla temsil etmeyi amaÃ§lar. Bu adÄ±mda, "Items in order" verilerinden kelime vektÃ¶rleri elde edilir.  
Model eÄŸitimi iÃ§in farklÄ± parametre kombinasyonlarÄ± kullanÄ±lÄ±r:
- **Model tipi**: CBOW (Continuous Bag of Words) veya Skip-gram
- **Pencere boyutu**: Bir kelimenin baÄŸlamÄ±nÄ± oluÅŸturan kelime sayÄ±sÄ± (Ã¶r. 2 veya 4)
- **VektÃ¶r boyutu**: Kelimelerin temsil edileceÄŸi vektÃ¶rlerin boyutu (Ã¶r. 100 veya 300)  
Model eÄŸitimi, kod klasÃ¶rÃ¼ndeki `word2vec.ipynb` dosyasÄ±nda gerÃ§ekleÅŸtirilmiÅŸtir.  
EÄŸitilen modeller, kullanÄ±lan parametreleri iÃ§erecek ÅŸekilde adlandÄ±rÄ±lmÄ±ÅŸ ve `model` klasÃ¶rÃ¼ne kaydedilmiÅŸtir (Ã¶rneÄŸin, `lemmatized_model_cbow_window2_dim100.model`).

### 2.6. Model DeÄŸerlendirmesi ve KullanÄ±mÄ±
EÄŸitilen Word2Vec modelleri, kelime benzerliÄŸi (Ã¶rneÄŸin, "pizza" ile "burger" arasÄ±ndaki iliÅŸki) ve kelime analojisi gibi gÃ¶revlerde deÄŸerlendirilebilir.  
Modelin performansÄ± ve elde edilen vektÃ¶rlerin kalitesi analiz edilerek en iyi performansÄ± gÃ¶steren modeller seÃ§ilebilir.

---

## Word2Vec Modeli

Bu proje, yemek sipariÅŸi aÃ§Ä±klamalarÄ± Ã¼zerinde **Word2Vec** modellerini eÄŸitmek ve kelime benzerliklerini analiz ederek kiÅŸiselleÅŸtirilmiÅŸ Ã¶neriler sunmak iÃ§in tasarlanmÄ±ÅŸtÄ±r.

### AdÄ±mlar

#### 1. Gerekli KÃ¼tÃ¼phanelerin Kurulumu
- **KullanÄ±lan AraÃ§lar**: `gensim` (Word2Vec modeli iÃ§in), `pandas` (veri iÅŸleme), `nltk` (metin iÅŸleme)
- **NLTK Paketleri**: Tokenizasyon, stopwords ve lemmatization iÃ§in gerekli paketler indirilir.

#### 2. Veri Setinin HazÄ±rlanmasÄ±
- **Veri KaynaklarÄ±**:
  - `lemmatized_sentences.csv`: Kelimelerin kÃ¶k hallerini iÃ§eren sipariÅŸ aÃ§Ä±klamalarÄ±
  - `stemmed_sentences.csv`: Kelime kÃ¶klerini iÃ§eren sipariÅŸ aÃ§Ä±klamalarÄ±
- **Temizlik Ä°ÅŸlemleri**:
  - NaN ve boÅŸ deÄŸerler temizlenir
  - Metinler Ã¶zel karakterlerden arÄ±ndÄ±rÄ±lÄ±r ve kÃ¼Ã§Ã¼k harfe Ã§evrilir
  - Stopwords ve tek karakterli kelimeler filtrelenir

#### 3. Veri Analizi ve VektÃ¶rleÅŸtirme
- **Model Parametreleri**:
  - **Model TÃ¼rÃ¼**: CBOW veya Skip-gram
  - **Pencere Boyutu**: 2 veya 4
  - **VektÃ¶r Boyutu**: 100 veya 300
- **EÄŸitim**:
  - Her parametre kombinasyonu iÃ§in ayrÄ± modeller eÄŸitilir
  - Modeller `.model` uzantÄ±sÄ±yla kaydedilir
- **Analiz**:
  - "angara" kelimesine en benzer 3 kelime ve skorlarÄ± Ã§Ä±karÄ±lÄ±r
  - Veri setindeki en sÄ±k kullanÄ±lan 20 kelime listelenir (Ã¶r. "pizza", "burger", "salad")

---

### SonuÃ§lar
- **Kaydedilen Modeller**: `lemmatized_model_cbow_vs100_w2.model`, `stemmed_model_skipgram_vs300_w4.model` gibi isimlerle kaydedilir.
- **Ã–rnek Ã‡Ä±ktÄ±lar**:
  - Kelime benzerlikleri yÃ¼ksek skorlarla raporlanÄ±r (Ã¶rneÄŸin, "pizza" â†” "burger": 0.9876)
  - En sÄ±k kullanÄ±lan kelimeler "pizza", "salad", "drink" gibi tematik terimlerdir

---

### NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?
1. **Veri YollarÄ±nÄ± GÃ¼ncelleyin**: CSV dosyalarÄ±nÄ±n doÄŸru konumunu belirtin.
2. **Jupyter Not Defterini BaÅŸlatÄ±n**: TÃ¼m hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n.
3. **SonuÃ§larÄ± GÃ¶rÃ¼ntÃ¼leyin**: Modeller ve analiz Ã§Ä±ktÄ±larÄ± otomatik olarak oluÅŸturulur.

---

Bu uyarlama, yemek sipariÅŸi verilerini kiÅŸiselleÅŸtirme hedefiyle orijinal projenin yapÄ±sÄ±nÄ± korurken, iÃ§eriÄŸi yemek sipariÅŸleri baÄŸlamÄ±na uygun hale getirilmiÅŸtir. "Items in order" sÃ¼tunu, sipariÅŸ aÃ§Ä±klamalarÄ±nÄ± temsil eder ve analizler bu verilere odaklanmÄ±ÅŸtÄ±r.
